{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018년\n",
      "01월\n",
      "01.01~01.07\n",
      "장르종합\n",
      "30806580\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NoSuchElementException' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9dbff27a8bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mcreator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//*[@id=\"conts\"]/div[3]/ul'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mNoSuchElementException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'driver' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9dbff27a8bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                         \u001b[0mcreator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//*[@id=\"conts\"]/div[3]/ul'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                     \u001b[0;32mexcept\u001b[0m \u001b[0mNoSuchElementException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                         \u001b[0mcreator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NoSuchElementException' is not defined"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "header = {'User-Agent': ''}\n",
    "d = webdriver.Chrome('./chromedriver')\n",
    "d.implicitly_wait(3)\n",
    "d.get('http://www.melon.com/chart/index.htm')\n",
    "d.get(\"http://www.melon.com/chart/search/index.htm\")\n",
    "d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/h4[1]/a').click()\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    # age\n",
    "    age_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[1]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "    age = d.find_element_by_xpath(age_xpath)\n",
    "    age.click()\n",
    "\n",
    "    # year\n",
    "    for i in range(1, 11):\n",
    "        result = list()\n",
    "\n",
    "        try:\n",
    "            year_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[2]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "            year = d.find_element_by_xpath(year_xpath)\n",
    "            year.click()\n",
    "            print(year.text)\n",
    "\n",
    "        except:\n",
    "            print(\"year_xpath not found\")\n",
    "            pass\n",
    "            \n",
    "        # month\n",
    "        for i in range(1,13):\n",
    "            try:\n",
    "                month_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[3]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "                month = d.find_element_by_xpath(month_xpath)\n",
    "                month.click()\n",
    "                print(month.text)\n",
    "\n",
    "            except:\n",
    "                print(\"month_xpath not found\")\n",
    "                pass\n",
    "        \n",
    "            # week\n",
    "            for i in range(1,6):\n",
    "                try:\n",
    "                    week_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[4]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "                    week = d.find_element_by_xpath(week_xpath)\n",
    "                    week.click()\n",
    "                    print(week.text)\n",
    "\n",
    "                except:\n",
    "                    print(\"week_xpath not found\")\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                # genre selection\n",
    "                classCd = d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li[2]/span/label')\n",
    "                if '가요' not in classCd.text or '국내종합' not in classCd.text:\n",
    "                    classCd = d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li/span/label')\n",
    "                classCd.click()\n",
    "                print(classCd.text)\n",
    "\n",
    "                # search button\n",
    "                d.find_element_by_xpath('//*[@id=\"d_srch_form\"]/div[2]/button/span/span').click()\n",
    "                sleep(10)\n",
    "\n",
    "                song_ids = d.find_elements_by_xpath('//*[@id=\"lst50\"]/td[4]/div/a')\n",
    "                song_ids = [re.sub('[^0-9]', '', song_id.get_attribute(\"href\")) for song_id in song_ids]\n",
    "                ranks = d.find_elements_by_xpath('//*[@id=\"lst50\"]/td[2]/div/span[1]')\n",
    "\n",
    "                for rank, song_id in zip(ranks, song_ids):\n",
    "                    sleep(5)\n",
    "                    print(song_id)\n",
    "\n",
    "                    req = requests.get('http://www.melon.com/song/detail.htm?songId=' + song_id, headers = header)\n",
    "                    html = req.text\n",
    "                    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "                    title = soup.find(attrs={\"class\": \"song_name\"}).text.replace('곡명', '')\n",
    "\n",
    "                    if '19금' in title:\n",
    "                        title = title.replace('19금', '')\n",
    "\n",
    "                    title = re.sub('^\\s*|\\s+$','', title)\n",
    "\n",
    "                    artist = soup.find(attrs={\"class\": \"artist_name\"}).text\n",
    "\n",
    "                    album = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[0].text\n",
    "                    date = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[1].text\n",
    "                    genre = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[2].text\n",
    "\n",
    "                    # consider case when more than 1 lyricist exists\n",
    "                    #lyricist = soup.select('//*[@id=\"conts\"]/div[3]/ul/li[1]/div[2]/div[1]/a')[0].text\n",
    "                    creator = []\n",
    "                    try:\n",
    "                        creator.append(driver.find_element_by_xpath('//*[@id=\"conts\"]/div[3]/ul').text)\n",
    "                    except NoSuchElementException as e:\n",
    "                        creator.append('')\n",
    "\n",
    "                    lyric = re.sub('<[^>]*>|\\s|\\[|\\]', ' ', str(soup.find_all(attrs={\"class\": \"lyric\"})[0]))\n",
    "                    lyric = re.sub('^\\s*|\\s+$', '', lyric)\n",
    "\n",
    "                    result.append({\n",
    "                        'year': re.sub('[^0-9]', '', year.text),\n",
    "                        'rank': rank.text,\n",
    "                        'title': title,\n",
    "                        'artist': artist,\n",
    "                        'album': album,\n",
    "                        'date' : date,\n",
    "                        'genre': genre,\n",
    "                        'creator': creator\n",
    "                        })\n",
    "                    print(\"차트 연도:\", year.text)\n",
    "                    print(\"순위:\", rank.text)\n",
    "                    print(\"곡 id:\", song_id)\n",
    "                    print(\"제목:\", title)\n",
    "                    print(\"아티스트:\", artist)\n",
    "                    print(\"앨범:\", album)\n",
    "                    print(\"발매날짜:\", date)\n",
    "                    print(\"장르:\", genre)\n",
    "                    print(\"작사:\", creator)\n",
    "                    print(\"*_*_*_*_*_*_*_*_*_*_*__*_*_*\")\n",
    "                with open('./data/melon_chart' + re.sub('[^0-9]', '', age.text) + 's.json', 'w', encoding='utf-8') as f:\n",
    "                    j = json.dumps(result)\n",
    "                    f.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018년\n",
      "01월\n",
      "01.01~01.07\n",
      "장르종합\n",
      "30806580\n",
      "차트 연도: 2018년\n",
      "순위: 1\n",
      "곡 id: 30806580\n",
      "제목: instagram\n",
      "아티스트: DEAN\n",
      "앨범: instagram\n",
      "발매날짜: 2017.12.26\n",
      "장르: R&B; / Soul\n",
      "작사: Deanfluenza ,  Deanfluenza ,  highhopes ,  Deanfluenza ,  highhopes ,  DEAN ,  DEAN ,  daebari88 ,  EZRAMILLER\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n",
      "30810765\n",
      "차트 연도: 2018년\n",
      "순위: 2\n",
      "곡 id: 30810765\n",
      "제목: 겨울소리\n",
      "아티스트: 박효신\n",
      "앨범: 겨울소리\n",
      "발매날짜: 2018.01.01\n",
      "장르: Ballad\n",
      "작사: 박효신 ,  김이나 ,  박효신 ,  정재일 ,  박효신 ,  감성에취하다 ,  레인트리뮤직\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n",
      "30086173\n",
      "차트 연도: 2018년\n",
      "순위: 3\n",
      "곡 id: 30086173\n",
      "제목: 비행운\n",
      "아티스트: 문문 (MoonMoon)\n",
      "앨범: LIFE IS BEAUTY FULL\n",
      "발매날짜: 2016.11.10\n",
      "장르: Rock\n",
      "작사: 문문 (MoonMoon) ,  문문 (MoonMoon) ,  문문 (MoonMoon) ,  김영철 ,  UoYo ,  daebari88\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n",
      "30755375\n",
      "차트 연도: 2018년\n",
      "순위: 4\n",
      "곡 id: 30755375\n",
      "제목: 그날처럼\n",
      "아티스트: 장덕철\n",
      "앨범: 그날처럼\n",
      "발매날짜: 2017.11.28\n",
      "장르: Ballad\n",
      "작사: 덕인 ,  덕인 ,  장중혁 ,  장중혁 ,  Harry ,  장덕철 ,  원밍 ,  FILTER77\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n",
      "30514366\n",
      "차트 연도: 2018년\n",
      "순위: 5\n",
      "곡 id: 30514366\n",
      "제목: 선물\n",
      "아티스트: 멜로망스\n",
      "앨범: Moonlight\n",
      "발매날짜: 2017.07.10\n",
      "장르: Ballad\n",
      "작사: 김민석 ,  멜로망스 ,  정동환 ,  멜로망스 ,  멜로망스 ,  UoYo ,  daebari88\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n",
      "30781481\n",
      "차트 연도: 2018년\n",
      "순위: 6\n",
      "곡 id: 30781481\n",
      "제목: Heart Shaker\n",
      "아티스트: TWICE (트와이스)\n",
      "앨범: Merry & Happy\n",
      "발매날짜: 2017.12.11\n",
      "장르: Dance\n",
      "작사: 별들의 전쟁 ,  David Amber ,  Sean Alexander ,  David Amber ,  Avenue 52 ,  TWICE (트와이스) ,  TWICE (트와이스) ,  몽차르트. ,  YES1619\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ce8ee3331505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "header = {'User-Agent': ''}\n",
    "d = webdriver.Chrome('./chromedriver')\n",
    "d.implicitly_wait(3)\n",
    "d.get('http://www.melon.com/chart/index.htm')\n",
    "d.get(\"http://www.melon.com/chart/search/index.htm\")\n",
    "d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/h4[1]/a').click()\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    # age\n",
    "    age_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[1]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "    age = d.find_element_by_xpath(age_xpath)\n",
    "    age.click()\n",
    "\n",
    "    # year\n",
    "    for i in range(1, 11):\n",
    "        result = list()\n",
    "\n",
    "        try:\n",
    "            year_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[2]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "            year = d.find_element_by_xpath(year_xpath)\n",
    "            year.click()\n",
    "            print(year.text)\n",
    "\n",
    "        except:\n",
    "            print(\"year_xpath not found\")\n",
    "            pass\n",
    "            \n",
    "        # month\n",
    "        for i in range(1,13):\n",
    "            try:\n",
    "                month_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[3]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "                month = d.find_element_by_xpath(month_xpath)\n",
    "                month.click()\n",
    "                print(month.text)\n",
    "\n",
    "            except:\n",
    "                print(\"month_xpath not found\")\n",
    "                pass\n",
    "        \n",
    "            # week\n",
    "            for i in range(1,6):\n",
    "                try:\n",
    "                    week_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[4]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "                    week = d.find_element_by_xpath(week_xpath)\n",
    "                    week.click()\n",
    "                    print(week.text)\n",
    "\n",
    "                except:\n",
    "                    print(\"week_xpath not found\")\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                # genre selection\n",
    "                classCd = d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li[2]/span/label')\n",
    "                if '가요' not in classCd.text or '국내종합' not in classCd.text:\n",
    "                    classCd = d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li/span/label')\n",
    "                classCd.click()\n",
    "                print(classCd.text)\n",
    "\n",
    "                # search button\n",
    "                d.find_element_by_xpath('//*[@id=\"d_srch_form\"]/div[2]/button/span/span').click()\n",
    "                sleep(10)\n",
    "\n",
    "                song_ids = d.find_elements_by_xpath('//*[@id=\"lst50\"]/td[4]/div/a')\n",
    "                song_ids = [re.sub('[^0-9]', '', song_id.get_attribute(\"href\")) for song_id in song_ids]\n",
    "                ranks = d.find_elements_by_xpath('//*[@id=\"lst50\"]/td[2]/div/span[1]')\n",
    "\n",
    "                for rank, song_id in zip(ranks, song_ids):\n",
    "                    sleep(5)\n",
    "                    print(song_id)\n",
    "\n",
    "                    req = requests.get('http://www.melon.com/song/detail.htm?songId=' + song_id, headers = header)\n",
    "                    html = req.text\n",
    "                    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "                    title = soup.find(attrs={\"class\": \"song_name\"}).text.replace('곡명', '')\n",
    "\n",
    "                    if '19금' in title:\n",
    "                        title = title.replace('19금', '')\n",
    "\n",
    "                    title = re.sub('^\\s*|\\s+$','', title)\n",
    "\n",
    "                    artist = soup.find(attrs={\"class\": \"artist_name\"}).text\n",
    "\n",
    "                    album = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[0].text\n",
    "                    date = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[1].text\n",
    "                    genre = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[2].text\n",
    "\n",
    "                    # consider case when more than 1 lyricist exists\n",
    "                    #lyricist = soup.select('//*[@id=\"conts\"]/div[3]/ul/li[1]/div[2]/div[1]/a')[0].text\n",
    "                    \n",
    "            \n",
    "                    \n",
    "                    try:\n",
    "                        #//*[@id=\"conts\"]/div[3]/ul/li[1]/div[2]/div[1]/a\n",
    "                        creator = re.sub('<[^>]*>|\\s|\\[|\\]', ' ', str(soup.find_all(attrs={\"class\": \"artist_name\"})[1:]))\n",
    "                        creator = re.sub('^\\s*|\\s+$', '', creator)\n",
    "                        #creator.append(d.find_element_by_xpath('//*[@id=\"conts\"]/div[3]/ul/li[1]/div[2]/div[2]/span').text)\n",
    "                    except NoSuchElementException as e:\n",
    "                        creator.append('')\n",
    "\n",
    "                    lyric = re.sub('<[^>]*>|\\s|\\[|\\]', ' ', str(soup.find_all(attrs={\"class\": \"lyric\"})[0]))\n",
    "                    lyric = re.sub('^\\s*|\\s+$', '', lyric)\n",
    "\n",
    "                    result.append({\n",
    "                        'year': re.sub('[^0-9]', '', year.text),\n",
    "                        'rank': rank.text,\n",
    "                        'title': title,\n",
    "                        'artist': artist,\n",
    "                        'album': album,\n",
    "                        'date' : date,\n",
    "                        'genre': genre,\n",
    "                        'creator' : creator\n",
    "                        })\n",
    "                    print(\"차트 연도:\", year.text)\n",
    "                    print(\"순위:\", rank.text)\n",
    "                    print(\"곡 id:\", song_id)\n",
    "                    print(\"제목:\", title)\n",
    "                    print(\"아티스트:\", artist)\n",
    "                    print(\"앨범:\", album)\n",
    "                    print(\"발매날짜:\", date)\n",
    "                    print(\"장르:\", genre)\n",
    "                    print(\"작사:\", creator)\n",
    "                    print(\"*_*_*_*_*_*_*_*_*_*_*__*_*_*\")\n",
    "                with open('./data/melon_chart' + re.sub('[^0-9]', '', age.text) + 's.json', 'w', encoding='utf-8') as f:\n",
    "                    j = json.dumps(result)\n",
    "                    f.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018년\n",
      "01월\n",
      "01.01~01.07\n",
      "장르종합\n",
      "30806580\n",
      "차트 연도: 2018년\n",
      "순위: 1\n",
      "곡 id: 30806580\n",
      "제목: instagram\n",
      "아티스트: ['DEAN', 'Deanfluenza', 'Deanfluenza', 'highhopes', 'Deanfluenza', 'highhopes', 'DEAN', 'DEAN', 'daebari88', 'EZRAMILLER']\n",
      "앨범: instagram\n",
      "발매날짜: 2017.12.26\n",
      "장르: R&B; / Soul\n",
      "작사: DEAN     ,  Deanfluenza ,  Deanfluenza ,  highhopes ,  Deanfluenza ,  highhopes ,  DEAN ,  DEAN ,  daebari88 ,  EZRAMILLER\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n",
      "30810765\n",
      "차트 연도: 2018년\n",
      "순위: 2\n",
      "곡 id: 30810765\n",
      "제목: 겨울소리\n",
      "아티스트: ['박효신', '박효신', '김이나', '박효신', '정재일', '박효신', '감성에취하다', '레인트리뮤직']\n",
      "앨범: 겨울소리\n",
      "발매날짜: 2018.01.01\n",
      "장르: Ballad\n",
      "작사: 박효신     ,  박효신 ,  김이나 ,  박효신 ,  정재일 ,  박효신 ,  감성에취하다 ,  레인트리뮤직\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n",
      "30086173\n",
      "차트 연도: 2018년\n",
      "순위: 3\n",
      "곡 id: 30086173\n",
      "제목: 비행운\n",
      "아티스트: ['문문 (MoonMoon)', '문문 (MoonMoon)', '문문 (MoonMoon)', '문문 (MoonMoon)', '김영철', 'UoYo', 'daebari88']\n",
      "앨범: LIFE IS BEAUTY FULL\n",
      "발매날짜: 2016.11.10\n",
      "장르: Rock\n",
      "작사: 문문 (MoonMoon)     ,  문문 (MoonMoon) ,  문문 (MoonMoon) ,  문문 (MoonMoon) ,  김영철 ,  UoYo ,  daebari88\n",
      "*_*_*_*_*_*_*_*_*_*_*__*_*_*\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-27ff58a94046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "header = {'User-Agent': ''}\n",
    "d = webdriver.Chrome('./chromedriver')\n",
    "d.implicitly_wait(3)\n",
    "d.get('http://www.melon.com/chart/index.htm')\n",
    "d.get(\"http://www.melon.com/chart/search/index.htm\")\n",
    "d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/h4[1]/a').click()\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    # age\n",
    "    age_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[1]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "    age = d.find_element_by_xpath(age_xpath)\n",
    "    age.click()\n",
    "\n",
    "    # year\n",
    "    for i in range(1, 11):\n",
    "        result = list()\n",
    "\n",
    "        try:\n",
    "            year_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[2]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "            year = d.find_element_by_xpath(year_xpath)\n",
    "            year.click()\n",
    "            print(year.text)\n",
    "\n",
    "        except:\n",
    "            print(\"year_xpath not found\")\n",
    "            pass\n",
    "            \n",
    "        # month\n",
    "        for i in range(1,13):\n",
    "            try:\n",
    "                month_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[3]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "                month = d.find_element_by_xpath(month_xpath)\n",
    "                month.click()\n",
    "                print(month.text)\n",
    "\n",
    "            except:\n",
    "                print(\"month_xpath not found\")\n",
    "                pass\n",
    "        \n",
    "            # week\n",
    "            for i in range(1,6):\n",
    "                try:\n",
    "                    week_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[4]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "                    week = d.find_element_by_xpath(week_xpath)\n",
    "                    week.click()\n",
    "                    print(week.text)\n",
    "\n",
    "                except:\n",
    "                    print(\"week_xpath not found\")\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                # genre selection\n",
    "                classCd = d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li[2]/span/label')\n",
    "                if '가요' not in classCd.text or '국내종합' not in classCd.text:\n",
    "                    classCd = d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li/span/label')\n",
    "                classCd.click()\n",
    "                print(classCd.text)\n",
    "\n",
    "                # search button\n",
    "                d.find_element_by_xpath('//*[@id=\"d_srch_form\"]/div[2]/button/span/span').click()\n",
    "                sleep(10)\n",
    "\n",
    "                song_ids = d.find_elements_by_xpath('//*[@id=\"lst50\"]/td[4]/div/a')\n",
    "                song_ids = [re.sub('[^0-9]', '', song_id.get_attribute(\"href\")) for song_id in song_ids]\n",
    "                ranks = d.find_elements_by_xpath('//*[@id=\"lst50\"]/td[2]/div/span[1]')\n",
    "\n",
    "                for rank, song_id in zip(ranks, song_ids):\n",
    "                    sleep(5)\n",
    "                    print(song_id)\n",
    "\n",
    "                    req = requests.get('http://www.melon.com/song/detail.htm?songId=' + song_id, headers = header)\n",
    "                    html = req.text\n",
    "                    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "                    title = soup.find(attrs={\"class\": \"song_name\"}).text.replace('곡명', '')\n",
    "\n",
    "                    if '19금' in title:\n",
    "                        title = title.replace('19금', '')\n",
    "\n",
    "                    title = re.sub('^\\s*|\\s+$','', title)\n",
    "                    singers = []\n",
    "                    for tag in soup.findAll('a', {'class':'artist_name'}):\n",
    "                        singer = tag.text\n",
    "                        singers.append(singer)\n",
    "                    #artist = soup.find_all(attrs={\"class\": \"artist_name\"})\n",
    "\n",
    "                    album = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[0].text\n",
    "                    date = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[1].text\n",
    "                    genre = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[2].text\n",
    "\n",
    "                    # consider case when more than 1 lyricist exists\n",
    "                    #lyricist = soup.select('//*[@id=\"conts\"]/div[3]/ul/li[1]/div[2]/div[1]/a')[0].text\n",
    "                    \n",
    "                    #creator = d.find_elements_by_class_name(\"artist_name\")\n",
    "                    #pre_elem = div_elem.find_element_by_class_name(\"ellipsis artist\")\n",
    "                    #creator = pre_elem.find_element_by_tag_name(\"a\")\n",
    "                    #creator = d.find_elements_by_css_selector('#conts > div.section_prdcr > ul > li:nth-child(1) > div.entry > div.ellipsis.artist')\n",
    "                    #soup.select('#conts > div.section_prdcr > ul > li:nth-child(1) > div.entry > div.ellipsis.artist > a')[:].text\n",
    "                        #//*[@id=\"conts\"]/div[3]/ul/li[1]/div[2]/div[1]/a\n",
    "                        \n",
    "                        #conts > div.section_prdcr > ul > li:nth-child(1) > div.entry > div.ellipsis.artist > a\n",
    "                        \n",
    "                    creator = re.sub('<[^>]*>|\\s|\\[|\\]', ' ', str(soup.find_all(\"a\", attrs={\"class\": \"artist_name\"})))\n",
    "                    creator = re.sub('^\\s*|\\s+$', '', creator)\n",
    "                        #creator.append(d.find_element_by_xpath('//*[@id=\"conts\"]/div[3]/ul/li[1]/div[2]/div[2]/span').text)\n",
    "                    #except NoSuchElementException as e:\n",
    "                    #    creator.append('')\n",
    "\n",
    "                    lyric = re.sub('<[^>]*>|\\s|\\[|\\]', ' ', str(soup.find_all(attrs={\"class\": \"lyric\"})[0]))\n",
    "                    lyric = re.sub('^\\s*|\\s+$', '', lyric)\n",
    "\n",
    "                    result.append({\n",
    "                        'year': re.sub('[^0-9]', '', year.text),\n",
    "                        'rank': rank.text,\n",
    "                        'title': title,\n",
    "                        'singers': singers,\n",
    "                        'album': album,\n",
    "                        'date' : date,\n",
    "                        'genre': genre,\n",
    "                        'creator' : creator\n",
    "                        })\n",
    "                    print(\"차트 연도:\", year.text)\n",
    "                    print(\"순위:\", rank.text)\n",
    "                    print(\"곡 id:\", song_id)\n",
    "                    print(\"제목:\", title)\n",
    "                    print(\"아티스트:\", singers)\n",
    "                    print(\"앨범:\", album)\n",
    "                    print(\"발매날짜:\", date)\n",
    "                    print(\"장르:\", genre)\n",
    "                    print(\"작사:\", creator)\n",
    "                    print(\"*_*_*_*_*_*_*_*_*_*_*__*_*_*\")\n",
    "                with open('./data/melon_chart' + re.sub('[^0-9]', '', age.text) + 's.json', 'w', encoding='utf-8') as f:\n",
    "                    j = json.dumps(result)\n",
    "                    f.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018년\n",
      "01월\n",
      "01.01~01.07\n",
      "국내종합\n",
      "yes\n",
      "장르종합\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-fc7687004dbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "header = {'User-Agent': ''}\n",
    "d = webdriver.Chrome('./chromedriver')\n",
    "d.implicitly_wait(3)\n",
    "d.get('http://www.melon.com/chart/index.htm')\n",
    "d.get(\"http://www.melon.com/chart/search/index.htm\")\n",
    "d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/h4[1]/a').click()\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    # age\n",
    "    age_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[1]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "    age = d.find_element_by_xpath(age_xpath)\n",
    "    age.click()\n",
    "\n",
    "    # year\n",
    "    for i in range(1, 11):\n",
    "        result = list()\n",
    "\n",
    "        try:\n",
    "            year_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[2]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "            year = d.find_element_by_xpath(year_xpath)\n",
    "            year.click()\n",
    "            print(year.text)\n",
    "\n",
    "        except:\n",
    "            print(\"year_xpath not found\")\n",
    "            pass\n",
    "            \n",
    "        # month\n",
    "        for i in range(1,13):\n",
    "            try:\n",
    "                month_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[3]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "                month = d.find_element_by_xpath(month_xpath)\n",
    "                month.click()\n",
    "                print(month.text)\n",
    "\n",
    "            except:\n",
    "                print(\"month_xpath not found\")\n",
    "                pass\n",
    "        \n",
    "            # week\n",
    "            for i in range(1,6):\n",
    "                try:\n",
    "                    week_xpath = '//*[@id=\"d_chart_search\"]/div/div/div[4]/div[1]/ul/li[' + str(i) + ']/span/label'\n",
    "                    week = d.find_element_by_xpath(week_xpath)\n",
    "                    week.click()\n",
    "                    print(week.text)\n",
    "\n",
    "                except:\n",
    "                    print(\"week_xpath not found\")\n",
    "                    pass\n",
    "                \n",
    "\n",
    "                # genre selection\n",
    "                classCd = d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li[2]/span/label')\n",
    "                if '가요' not in classCd.text and '국내종합' not in classCd.text:\n",
    "                    print(classCd.text)\n",
    "                    print('yes')\n",
    "                    classCd = d.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li/span/label')\n",
    "                classCd.click()\n",
    "                print(classCd.text)\n",
    "\n",
    "                # search button\n",
    "                d.find_element_by_xpath('//*[@id=\"d_srch_form\"]/div[2]/button/span/span').click()\n",
    "                sleep(10)\n",
    "\n",
    "                song_ids = d.find_elements_by_xpath('//*[@id=\"lst50\"]/td[4]/div/a')\n",
    "                song_ids = [re.sub('[^0-9]', '', song_id.get_attribute(\"href\")) for song_id in song_ids]\n",
    "                ranks = d.find_elements_by_xpath('//*[@id=\"lst50\"]/td[2]/div/span[1]')\n",
    "\n",
    "                for rank, song_id in zip(ranks, song_ids):\n",
    "                    sleep(5)\n",
    "                    print(song_id)\n",
    "\n",
    "                    req = requests.get('http://www.melon.com/song/detail.htm?songId=' + song_id, headers = header)\n",
    "                    html = req.text\n",
    "                    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "                    title = soup.find(attrs={\"class\": \"song_name\"}).text.replace('곡명', '')\n",
    "\n",
    "                    if '19금' in title:\n",
    "                        title = title.replace('19금', '')\n",
    "\n",
    "                    title = re.sub('^\\s*|\\s+$','', title)\n",
    "                    \n",
    "                    singers = re.sub('<[^>]*>|\\s|\\[|\\]', '', str(soup.find('div', class_ = \"artist\")))\n",
    "\n",
    "                    album = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[0].text\n",
    "                    date = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[1].text\n",
    "                    genre = soup.select('#downloadfrm > div > div > div.entry > div.meta > dl > dd')[2].text \n",
    "                    \n",
    "                    list_ = singers.split(',')\n",
    "                    count = len(list_)\n",
    "                    \n",
    "                    creator = re.sub('<[^>]*>|\\s|\\[|\\]', '', str(soup.find_all(\"div\", attrs={\"class\": \"entry\"})))\n",
    "                    creator = re.sub('^\\s*|\\s+$', '', creator)\n",
    "                    clist = creator.split(',')\n",
    "                    creator = []\n",
    "                    for x in clist:\n",
    "                        if '작사' in x:\n",
    "                            creator.append(x[:-2])\n",
    "                    creator = ','.join(creator)        \n",
    "                    lyric = re.sub('<[^>]*>|\\s|\\[|\\]', ' ', str(soup.find_all(attrs={\"class\": \"lyric\"})[0]))\n",
    "                    lyric = re.sub('^\\s*|\\s+$', '', lyric)\n",
    "\n",
    "                    result.append({\n",
    "                        'year': re.sub('[^0-9]', '', year.text),\n",
    "                        'rank': rank.text,\n",
    "                        'title': title,\n",
    "                        'singers': singers,\n",
    "                        'album': album,\n",
    "                        'date' : date,\n",
    "                        'genre': genre,\n",
    "                        'creator' : creator,\n",
    "                        'lyric' : lyric\n",
    "                        })\n",
    "                    print(\"차트 연도:\", year.text)\n",
    "                    print(\"순위:\", rank.text)\n",
    "                    print(\"곡 id:\", song_id)\n",
    "                    print(\"제목:\", title)\n",
    "                    print(\"아티스트:\", singers)\n",
    "                    print(\"앨범:\", album)\n",
    "                    print(\"발매날짜:\", date)\n",
    "                    print(\"장르:\", genre)\n",
    "                    print(\"작사:\", creator)\n",
    "                    print(\"가사:\", lyric)\n",
    "                    print(\"*_*_*_*_*_*_*_*_*_*_*__*_*_*\")\n",
    "                with open('./data/melon_chart' + re.sub('[^0-9]', '', age.text) + 's.json', 'w', encoding='utf-8') as f:\n",
    "                    j = json.dumps(result)\n",
    "                    f.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from urllib.request import urlopen\n",
    "#url = 'https://www.melon.com/song/detail.htm?songId=30729198'\n",
    "#html = urlopen(url).read()\n",
    "req = requests.get('https://www.melon.com/song/detail.htm?songId=3973781')\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "album = soup.find_all('div')\n",
    "print(album)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
